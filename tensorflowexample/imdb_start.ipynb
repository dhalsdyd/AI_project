{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "np.random.seed(0)\r\n",
    "df = pd.read_csv('movie_data.csv',encoding = 'utf-8')\r\n",
    "df.head(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  In 1974, the teenager Martha Moxley (Maggie Gr...  1\n",
       "1  OK... so... I really like Kris Kristofferson a...  0\n",
       "2  ***SPOILER*** Do not read this, if you think a...  0"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import numpy as np\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "\r\n",
    "count = CountVectorizer()\r\n",
    "docs = np.array([\r\n",
    "        'The sun is shining',\r\n",
    "        'The weather is sweet',\r\n",
    "        'The sun is shining, the weather is sweet, and one and one is two'])\r\n",
    "bag = count.fit_transform(docs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "count.vocabulary_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'the': 6,\n",
       " 'sun': 4,\n",
       " 'is': 1,\n",
       " 'shining': 3,\n",
       " 'weather': 8,\n",
       " 'sweet': 5,\n",
       " 'and': 0,\n",
       " 'one': 2,\n",
       " 'two': 7}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "bag.toarray()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 1, 0, 1],\n",
       "       [2, 3, 2, 1, 1, 1, 2, 1, 1]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
    "\r\n",
    "tfidf = TfidfTransformer(use_idf=True, \r\n",
    "                         norm='l2', \r\n",
    "                         smooth_idf=True)\r\n",
    "print(tfidf.fit_transform(count.fit_transform(docs))\r\n",
    "      .toarray())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.         0.43370786 0.         0.55847784 0.55847784 0.\n",
      "  0.43370786 0.         0.        ]\n",
      " [0.         0.43370786 0.         0.         0.         0.55847784\n",
      "  0.43370786 0.         0.55847784]\n",
      " [0.50238645 0.44507629 0.50238645 0.19103892 0.19103892 0.19103892\n",
      "  0.29671753 0.25119322 0.19103892]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "\r\n",
    "import re\r\n",
    "def preprocessor(text):\r\n",
    "    text = re.sub('<[^>]*>', '', text)\r\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\r\n",
    "                           text)\r\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) +\r\n",
    "            ' '.join(emoticons).replace('-', ''))\r\n",
    "    return text\r\n",
    "df.columns=['review','sentiment']\r\n",
    "df['review'] = df['review'].apply(preprocessor)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from nltk.stem.porter import PorterStemmer\r\n",
    "\r\n",
    "porter = PorterStemmer()\r\n",
    "\r\n",
    "def tokenizer(text):\r\n",
    "    return text.split()\r\n",
    "\r\n",
    "\r\n",
    "def tokenizer_porter(text):\r\n",
    "    return [porter.stem(word) for word in text.split()]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import nltk\r\n",
    "\r\n",
    "nltk.download('stopwords')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SAMSUNG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from nltk.corpus import stopwords\r\n",
    "\r\n",
    "stop = stopwords.words('english')\r\n",
    "[w for w in tokenizer_porter('a runner likes running and runs a lot')[-10:]\r\n",
    "if w not in stop]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['runner', 'like', 'run', 'run', 'lot']"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "\r\n",
    "X_train = df.loc[:2500, 'review'].values\r\n",
    "y_train = df.loc[:2500, 'sentiment'].values\r\n",
    "X_test = df.loc[:5000, 'review'].values\r\n",
    "y_test = df.loc[:5000, 'sentiment'].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "\r\n",
    "tfidf = TfidfVectorizer(strip_accents=None,\r\n",
    "                        lowercase=False,\r\n",
    "                        preprocessor=None)\r\n",
    "\r\n",
    "param_grid = [{'vect__ngram_range': [(1, 1)],\r\n",
    "               'vect__stop_words': [stop, None],\r\n",
    "               'vect__tokenizer': [tokenizer, tokenizer_porter],\r\n",
    "               'clf__penalty': ['l1', 'l2'],\r\n",
    "               'clf__C': [1.0, 10.0, 100.0]},\r\n",
    "              {'vect__ngram_range': [(1, 1)],\r\n",
    "               'vect__stop_words': [stop, None],\r\n",
    "               'vect__tokenizer': [tokenizer, tokenizer_porter],\r\n",
    "               'vect__use_idf':[False],\r\n",
    "               'vect__norm':[None],\r\n",
    "               'clf__penalty': ['l1', 'l2'],\r\n",
    "               'clf__C': [1.0, 10.0, 100.0]},\r\n",
    "              ]\r\n",
    "\r\n",
    "lr_tfidf = Pipeline([('vect', tfidf),\r\n",
    "                     ('clf', LogisticRegression(solver='liblinear', random_state=0))])\r\n",
    "\r\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,\r\n",
    "                           scoring='accuracy',\r\n",
    "                           cv=5,\r\n",
    "                           verbose=1,\r\n",
    "                           n_jobs=-1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "gs_lr_tfidf.fit(X_train, y_train)\r\n",
    "'''\r\n",
    "최적의 매개변수 조합: {'clf__C': 10.0, 'clf__penalty': 'l2', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x7f4387eb0950>} \r\n",
    "CV 정확도: 0.897\r\n",
    "'''"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\n최적의 매개변수 조합: {'clf__C': 10.0, 'clf__penalty': 'l2', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x7f4387eb0950>} \\nCV 정확도: 0.897\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "gs_lr_tfidf.best_score_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8580630738522954"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "09d8611f38b064ca2594bca0cde57f51ccc32e33177f657a36872d444ba23277"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}